{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp diff_scratch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env PYDEVD_DISABLE_FILE_VALIDATION=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "#from diffusers import DDPMScheduler, UNet2DModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from cop_diffusion.utils import save_model, load_model\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"mnist/\", train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(train_dataloader))\n",
    "oh_y = torch.nn.functional.one_hot(y)\n",
    "ic(\"Input shape:\", x.shape)\n",
    "ic(\"Labels:\", y)\n",
    "plt.imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corruption process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand_like(x)\n",
    "amount = .2\n",
    "noisy_x = (1-amount)*x + amount*noise\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15, 5))\n",
    "axs[0].set_title(\"100% of X\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n",
    "\n",
    "axs[1].set_title(f\"1-Amount {1-amount} of X\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(x*(1-amount))[0], cmap=\"Greys\")\n",
    "\n",
    "axs[2].set_title(f\"Amount {amount} of noise\")\n",
    "axs[2].imshow(torchvision.utils.make_grid(noise*amount)[0], cmap=\"Greys\")\n",
    "\n",
    "\n",
    "axs[3].set_title(f\"Noisy image: 1-{amount} of x, {amount} of noise\")\n",
    "axs[3].imshow(torchvision.utils.make_grid(noisy_x)[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt(x, amount):\n",
    "    \"\"\"Corrupt the input `x` by mixing it with noise according to `amount`\"\"\"\n",
    "    noise = torch.rand_like(x)\n",
    "    amount = amount.view(-1, 1, 1, 1)  # Sort shape so broadcasting works\n",
    "    return x * (1 - amount) + noise * amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the input data\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 5))\n",
    "axs[0].set_title(\"Input data\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n",
    "\n",
    "# Adding noise\n",
    "amount = torch.linspace(0, 1, x.shape[0])\n",
    "print(amount)  # Left to right -> more corruption\n",
    "noised_x = corrupt(x, amount)\n",
    "\n",
    "# Plotting the noised version\n",
    "axs[1].set_title(\"Corrupted data (-- amount increases -->)\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(noised_x)[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to learn noise\n",
    "\n",
    "We’d like a model that takes in a 28px noisy images and outputs a prediction of the same shape.\n",
    "\n",
    "**UNet** consists of a ‘constricting path’ through which data is compressed down and an ‘expanding path’ through which it expands back up to the original dimension (similar to an autoencoder) but also features skip connections that allow for information and gradients to flow across at different levels.\n",
    "\n",
    "![UNET](../res/unet.png)\n",
    "\n",
    "\n",
    "### See convolution_101.ipynb for better understanding of convolutions\n",
    "\n",
    "![Convolution_101](./convolution_101.ipynb)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "class BasicUNetOld(nn.Module):\n",
    "    \"\"\"A minimal UNet implementation.\"\"\"\n",
    "    #TODO: add time embedding and a class embedding\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, ctx_nb_feats:int=0):\n",
    "        super().__init__()\n",
    "        self.down_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(in_channels, 32, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            ]\n",
    "        )\n",
    "        self.time_embeds = nn.ModuleList([nn.Embedding(1,64), nn.Embedding(1,32)])\n",
    "        self.ctx_embeds = nn.ModuleList([nn.Embedding(ctx_nb_feats,64), nn.Embedding(ctx_nb_feats,32)])\n",
    "        self.up_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(32, out_channels, kernel_size=5, padding=2),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.act = nn.SiLU()  # The activation function\n",
    "        self.downscale = nn.MaxPool2d(2)\n",
    "        self.upscale = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, x, t, c=None):\n",
    "        h = []\n",
    "        for i, l in enumerate(self.down_layers):\n",
    "            x = self.act(l(x))  # Through the layer and the activation function\n",
    "            if i < 2:  # For all but the third (final) down layer:\n",
    "                h.append(x)  # Storing output for skip connection\n",
    "                x = self.downscale(x)  # Downscale ready for the next layer\n",
    "        ic(\"after downscale layers\", x.shape)\n",
    "        for i, l in enumerate(self.up_layers):\n",
    "\n",
    "            if i > 0:  # For all except the first up layer\n",
    "                ic(\"before upscale\",i, x.shape)\n",
    "                x = self.upscale(x)  # Upscale\n",
    "                ic(\"after upscale\",i,x.shape)\n",
    "\n",
    "                x += h.pop()  # Fetching stored output (skip connection)\n",
    "                h_dim  = x.shape[1] # the dim of hidden\n",
    "                t_emb = self.time_embeds[i-1](t).view(-1, h_dim, 1,1)\n",
    "                ctx_emb = self.ctx_embeds[i-1](c).view(-1, h_dim, 1,1)\n",
    "                ic(x.shape, ctx_emb.shape, t_emb.shape)\n",
    "                x = ctx_emb * x + t_emb\n",
    "            ic(\"before uplayer + activation\",i, x.shape)\n",
    "            x = self.act(l(x))  # Through the layer and the activation function\n",
    "            ic(\"after uplayer + activation\",i, x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = BasicUNetOld().to(device)\n",
    "#x = torch.rand(8, 1, 28, 28)\n",
    "t = torch.zeros(x.shape[0]).long().to(device)\n",
    "#oh_y = oh_y.to(device)\n",
    "x = x.to(device)\n",
    "ic(t.shape, y.shape)\n",
    "ux = model(x,t, y)\n",
    "ic(ux.shape, x.shape)\n",
    "plt.imshow(torchvision.utils.make_grid(x.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "plt.imshow(torchvision.utils.make_grid(ux.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, ctx_nb_feats:int=0):\n",
    "        super().__init__()\n",
    "        self.d1 = nn.Conv2d(in_channels, 64, kernel_size=5, padding=2)\n",
    "        self.d2 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
    "        self.d3 = nn.Conv2d(128, 256, kernel_size=5, padding=2)\n",
    "\n",
    "        self.u1= nn.Conv2d(256, 128, kernel_size=5, padding=2)\n",
    "        self.u2= nn.Conv2d(128, 64, kernel_size=5, padding=2)\n",
    "        self.u3= nn.Conv2d(64, out_channels, kernel_size=5, padding=2)\n",
    "\n",
    "        self.ce2 = nn.Embedding(ctx_nb_feats,128)\n",
    "        self.te2 = nn.Embedding(1,128)\n",
    "\n",
    "        self.ce3 = nn.Embedding(ctx_nb_feats,64)\n",
    "        self.te3 = nn.Embedding(1,64)\n",
    "\n",
    "        self.act = nn.SiLU()\n",
    "        self.downsample = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "\n",
    "    def forward(self, x, t, c=None):\n",
    "        xd1 = self.act(self.d1(x))\n",
    "        xmd1 = self.downsample(xd1)\n",
    "        xd2 = self.act(self.d2(xmd1))\n",
    "        xmd2 =self.downsample(xd2)\n",
    "        xd3 = self.act(self.d3(xmd2))\n",
    "\n",
    "        xu1 = self.act(self.u1(xd3))\n",
    "        xus2 = self.upsample(xu1)\n",
    "        xus2 = xus2 + xd2\n",
    "        h2_dim  = xus2.shape[1] # the dim of hidden\n",
    "        t2_emb = self.te2(t).view(-1, h2_dim, 1,1)\n",
    "        c2_emb = self.ce2(c).view(-1, h2_dim, 1,1)\n",
    "        xus2 = c2_emb * xus2 + t2_emb\n",
    "        xu2 = self.act(self.u2(xus2))\n",
    "\n",
    "        xus3 = self.upsample(xu2)\n",
    "        xus3 = xus3 + xd1\n",
    "        h3_dim  = xus3.shape[1] # the dim of hidden\n",
    "        t3_emb = self.te3(t).view(-1, h3_dim, 1,1)\n",
    "        c3_emb = self.ce3(c).view(-1, h3_dim, 1,1)\n",
    "        xus2 = c3_emb * xus3 + t3_emb\n",
    "        xu3 = self.act(self.u3(xus3))\n",
    "\n",
    "        return xu3\n",
    "\n",
    "\n",
    "model = BasicUNet().to(device)\n",
    "#x = torch.rand(8, 1, 28, 28)\n",
    "t = torch.zeros(x.shape[0]).long().to(device)\n",
    "#oh_y = oh_y.to(device)\n",
    "x = x.to(device)\n",
    "ic(t.shape, y.shape)\n",
    "ux = model(x,t, y)\n",
    "ic(ux.shape, x.shape)\n",
    "plt.imshow(torchvision.utils.make_grid(x.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "plt.imshow(torchvision.utils.make_grid(ux.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channel(input, channel_nb:int=0, info=\"\"):\n",
    "    '''You must provide on image of shape (batch, channel, height, width)convolved on many channels'''\n",
    "    title = f\"channel {channel_nb}, info: {info}\"\n",
    "    img = input[channel_nb].cpu().detach().numpy()\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")  # Turn off axis labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=1\n",
    "out_channels=1\n",
    "ic(x.shape)\n",
    "c0 = nn.Conv2d(in_channels, 32, kernel_size=5, padding=2).to(device)(x)\n",
    "ic(c0.shape);\n",
    "downscale = nn.MaxPool2d(2).to(device)\n",
    "cd0 = downscale(c0)\n",
    "ic(cd0.shape)\n",
    "show_channel(cd0[0],channel_nb=0, info='conv 0 -> downscale' )\n",
    "show_channel(cd0[0],channel_nb=31, info='conv 0 -> downscale' )\n",
    "\n",
    "\n",
    "c1 = nn.Conv2d(32, 64, kernel_size=5, padding=2).to(device)(cd0)\n",
    "cd1 = downscale(c1)\n",
    "ic(cd1.shape)\n",
    "show_channel(cd1[0], channel_nb=63,info='conv 1 -> downscale' )\n",
    "\n",
    "# Decoding part\n",
    "upscale = nn.Upsample(scale_factor=2).to(device)\n",
    "u0 = upscale(cd1)\n",
    "ic(u0.shape)\n",
    "show_channel(u0[0],channel_nb=0, info='upscale')\n",
    "uc0 = nn.Conv2d(64, 64, kernel_size=5, padding=2).to(device)(u0)\n",
    "show_channel(uc0[:,0],channel_nb=0, info='upscale -> conv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the UNet model (DDPM)\n",
    "\n",
    "https://github.com/nickd16/Diffusion-Models-from-Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM_Scheduler(nn.Module):\n",
    "    def __init__(self, num_time_steps: int=1000):\n",
    "        super().__init__()\n",
    "        self.beta = torch.linspace(1e-4, 0.02, num_time_steps, requires_grad=False)\n",
    "        alpha = 1 - self.beta\n",
    "        self.alpha = torch.cumprod(alpha, dim=0).requires_grad_(False)\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.beta[t], self.alpha[t]\n",
    "\n",
    "scheduler = DDPM_Scheduler(num_time_steps=1000)\n",
    "ic(scheduler(999))\n",
    "ic(scheduler(0));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a very tiny dataset to overfit the training and validate the model has enough capacity to have a loss of 0.\n",
    "random_indices = torch.randperm(len(train_dataset))[:10]\n",
    "train_tiny_dataset = Subset(train_dataset, random_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_time_steps = 500\n",
    "scheduler = DDPM_Scheduler(num_time_steps=num_time_steps).to(device)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "use_tiny_dataset = True\n",
    "do_train:bool=True\n",
    "if use_tiny_dataset:\n",
    "    n_epoch = 2000\n",
    "    n_epoch = 1\n",
    "else:\n",
    "    n_epoch = 5\n",
    "last_epoch = 0\n",
    "\n",
    "model_version = \"0.2\"\n",
    "model_name = f\"mnist_{'tiny_' if use_tiny_dataset else ''}ddpm_time_emb\"\n",
    "\n",
    "if do_train:\n",
    "    if use_tiny_dataset:\n",
    "        train_dataloader = DataLoader(train_tiny_dataset, batch_size=5, shuffle=True)\n",
    "    else:\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    if last_epoch > 0:\n",
    "        model = load_model(\n",
    "            model_name=model_name, model_version=model_version, iter=last_epoch\n",
    "        )\n",
    "        from_epoch_nb = last_epoch + 1\n",
    "    else:\n",
    "        model = BasicUNet().to(device)\n",
    "        from_epoch_nb = 0\n",
    "\n",
    "    writer = SummaryWriter(\n",
    "            f\"../runs/{model_name}_{model_version}/{datetime.now().strftime('%m-%d-%Y_%H:%M:%S')}\"\n",
    "        )\n",
    "    log_interval:int=50\n",
    "    # The training loop\n",
    "    criterion = nn.MSELoss(reduction='mean')#.to(device)\n",
    "    lr=2e-5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    nb_batches = len(train_dataloader)\n",
    "    with tqdm(\n",
    "        total=(n_epoch+1-from_epoch_nb) * nb_batches,\n",
    "        desc=f\"Training update\",\n",
    "        unit=\"batch\",\n",
    "    ) as pbar:\n",
    "        for epoch in range(from_epoch_nb, n_epoch+1):\n",
    "            total_loss = 0\n",
    "            for batch_nb, (x, y) in enumerate(train_dataloader):\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                n,c,w,h = x.shape\n",
    "                # we may exhaust the loader and have a smaller batch\n",
    "                t = torch.randint(0, num_time_steps,(n,))\n",
    "                noise = torch.randn_like(x, requires_grad=False).to(device)\n",
    "                a = scheduler.alpha[t].view(n,1,1,1).to(device)\n",
    "                #ic(t.shape, e.shape, a.shape)\n",
    "                x = (torch.sqrt(a)*x) + (torch.sqrt(1-a)*noise)\n",
    "                #ic(next(model.parameters()).device, x.device, t.device,y.device)\n",
    "\n",
    "                output = model(x, t.to(device),y)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(output, noise)\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                i = (epoch*nb_batches) + batch_nb\n",
    "                writer.add_scalar(f\"train loss\", loss.item(), (epoch*nb_batches) + batch_nb)\n",
    "                if i % log_interval == 0:\n",
    "                    for name, kernel_weight in model.named_parameters():\n",
    "                        if kernel_weight.numel() > 0:\n",
    "                            writer.add_histogram(name, kernel_weight, i)\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_nb\": batch_nb,\n",
    "                        #\"train_loss\": f\"{loss.item():.4f}\",\n",
    "                    })\n",
    "                ...\n",
    "        if not use_tiny_dataset:\n",
    "            save_model(model=model, model_name=model_name, model_version=model_version, iter=epoch)\n",
    "else:\n",
    "    if not use_tiny_dataset:\n",
    "        model = load_model(model_name=model_name, model_version=model_version, iter=last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "- it look loss get to 0.45 after 10 epochs and stay there\n",
    "- with this model with a tiny dataset (10 examples) it cannot go lower than 0.45 after 1000 or 5000 epochs\n",
    "- Enhance the model by adding capacity and by checking it overfit to 0 loss with a very small dataset (like 5 samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_time_steps\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(1, 1, 32, 32).to(device)\n",
    "t =  torch.tensor([10]).to(device)\n",
    "c = torch.tensor([1]).to(device)\n",
    "scheduler = scheduler.to(device)\n",
    "#temp = (scheduler.beta[t]/( (torch.sqrt(1-scheduler.alpha[t]))*(torch.sqrt(1-scheduler.beta[t])) ))\n",
    "#z = (1/(torch.sqrt(1-scheduler.beta[t])))*z - (temp*model(z.to(device),t=[0]).cpu())\n",
    "scheduler.beta[t]\n",
    "#(1/(torch.sqrt(1-scheduler.beta[t])))*z\n",
    "#model(z,t=t,c=c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_reverse(images: list):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(10,1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        x = images[i].squeeze(0)\n",
    "        #x = torch.rearrange(x, 'c h w -> h w c')\n",
    "        x = x.permute(1,2,0)\n",
    "        x = x.numpy()\n",
    "        ax.imshow(x)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
    "times = [0,15,50,100,200,300,400,499]\n",
    "images = []\n",
    "with torch.no_grad():\n",
    "    model = model.eval()\n",
    "    for i in range(10):\n",
    "        z = torch.randn(1, 1, 32, 32)\n",
    "        for t in reversed(range(1, num_time_steps)):\n",
    "            t = [t]\n",
    "            temp = (scheduler.beta[t]/( (torch.sqrt(1-scheduler.alpha[t]))*(torch.sqrt(1-scheduler.beta[t])) ))\n",
    "            z = (1/(torch.sqrt(1-scheduler.beta[t])))*z - (temp*model(z.to(device),t=[0]).cpu())\n",
    "            if t[0] in times:\n",
    "                images.append(z)\n",
    "            e = torch.randn(1, 1, 32, 32)\n",
    "            z = z + (e*torch.sqrt(scheduler.beta[t]))\n",
    "        temp = scheduler.beta[0]/( (torch.sqrt(1-scheduler.alpha[0]))*(torch.sqrt(1-scheduler.beta[0])) )\n",
    "        y = torch.randint(0,9,(1,1)).to(device)\n",
    "        z_pred =model(z.to(device),t=[0],c=y)\n",
    "        ic(z_pred.shape)\n",
    "        x = (1/(torch.sqrt(1-scheduler.beta[0])))*z - (temp*z_pred.cpu())\n",
    "\n",
    "        images.append(x)\n",
    "        #x = torch.rearrange(x.squeeze(0), 'c h w -> h w c').detach()\n",
    "        ic(x.shape, x.squeeze(0).shape)\n",
    "        x = x.squeeze(0).permute( 1,2,0).detach()\n",
    "        x = x.numpy()\n",
    "        plt.imshow(x)\n",
    "        plt.show()\n",
    "        display_reverse(images)\n",
    "        images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the UNet model\n",
    "\n",
    "Difference with DDPM method.\n",
    "\n",
    "The training objective is different, involving predicting the noise rather than the denoised image\n",
    "\n",
    "The model is conditioned on the amount of noise present via timestep conditioning, where t is passed as an additional argument to the forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"0.1\"\n",
    "model_name = \"mnist_diffus\"\n",
    "\n",
    "\n",
    "# Dataloader (you can mess with batch size)\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# How many runs through the data should we do?\n",
    "n_epoch = 3\n",
    "\n",
    "# Create the network\n",
    "model = BasicUNet()\n",
    "model.to(device)\n",
    "\n",
    "# Our loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# The optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses = []\n",
    "\n",
    "do_train: bool = True\n",
    "last_update_epoch = 0\n",
    "\n",
    "if do_train:\n",
    "    writer = SummaryWriter(\n",
    "        f\"../runs/{model_name}_{model_version}/{datetime.now().strftime('%m-%d-%Y_%H:%M:%S')}\"\n",
    "    )\n",
    "    # The training loop\n",
    "    nb_batches = len(train_dataloader)\n",
    "    with tqdm(\n",
    "        total=n_epoch * nb_batches,\n",
    "        desc=f\"Training update\",\n",
    "        unit=\"batch\",\n",
    "    ) as pbar:\n",
    "        for epoch in range(n_epoch):\n",
    "            for batch_nb, (x, y) in enumerate(train_dataloader):\n",
    "                # Get some data and prepare the corrupted version\n",
    "                x = x.to(device)  # Data on the GPU\n",
    "                noise_amount = torch.rand(x.shape[0]).to(\n",
    "                    device\n",
    "                )  # Pick random noise amounts\n",
    "                noisy_x = corrupt(x, noise_amount)  # Create our noisy x\n",
    "\n",
    "                # Get the model prediction\n",
    "                pred = model(noisy_x)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss = loss_fn(\n",
    "                    pred, x\n",
    "                )  # How close is the output to the true 'clean' x?\n",
    "\n",
    "                # Backprop and update the params:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                # Store the loss for later\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_nb\": batch_nb,\n",
    "                        \"train_loss\": f\"{loss.item():.4f}\",\n",
    "                    }\n",
    "                )\n",
    "                writer.add_scalar(f\"train loss\", loss.item(), (epoch*nb_batches) + batch_nb)\n",
    "\n",
    "            for name, kernel_weight in model.named_parameters():\n",
    "                writer.add_histogram(name, kernel_weight, epoch)\n",
    "\n",
    "            # Print our the average of the loss values for this epoch:\n",
    "            avg_loss = sum(losses[nb_batches :]) / nb_batches\n",
    "            # print(f\"Finished epoch {epoch}. Average loss for this epoch: {avg_loss:05f}\")\n",
    "\n",
    "    # View the loss curve\n",
    "    plt.plot(losses)\n",
    "    plt.ylim(0, 0.25)\n",
    "\n",
    "\n",
    "    save_model(model=model, model_name=model_name, model_version=model_version, iter=epoch)\n",
    "else:\n",
    "    model = load_model(model_name=model_name, model_version=model_version, iter=last_update_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction without any noise added.\n",
    "\n",
    "dl = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(dl))\n",
    "with torch.no_grad():\n",
    "    ux = model(x.to(device))\n",
    "    ic(ux.shape)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 5))\n",
    "axs[0].set_title(\"Input\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n",
    "axs[1].set_title(\"Reconstructed\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(ux.cpu())[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrupt with a range of amounts\n",
    "amount = torch.linspace(0, 1, x.shape[0])  # Left to right -> more corruption\n",
    "noised_x = corrupt(x, amount)\n",
    "\n",
    "# Get the model predictions\n",
    "with torch.no_grad():\n",
    "    preds = model(noised_x.to(device)).detach().cpu()\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 7))\n",
    "axs[0].set_title(\"Input data\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0].clip(0, 1), cmap=\"Greys\")\n",
    "axs[1].set_title(\"Corrupted data\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(noised_x)[0].clip(0, 1), cmap=\"Greys\")\n",
    "axs[2].set_title(\"Network Predictions\")\n",
    "axs[2].imshow(torchvision.utils.make_grid(preds)[0].clip(0, 1), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Sampling strategy: Break the process into 5 steps and move 1/5'th of the way there each time:\n",
    "n_steps = 5\n",
    "x = torch.rand(8, 1, 28, 28).to(device)  # Start from random\n",
    "step_history = [x.detach().cpu()]\n",
    "pred_output_history = []\n",
    "\n",
    "for i in range(n_steps):\n",
    "    with torch.no_grad():  # No need to track gradients during inference\n",
    "        pred = model(x)  # Predict the denoised x0\n",
    "    pred_output_history.append(pred.detach().cpu())  # Store model output for plotting\n",
    "    mix_factor = 1 / (n_steps - i)  # How much we move towards the prediction\n",
    "    x = x * (1 - mix_factor) + pred * mix_factor  # Move part of the way there\n",
    "    step_history.append(x.detach().cpu())  # Store step for plotting\n",
    "\n",
    "fig, axs = plt.subplots(n_steps, 2, figsize=(9, 4), sharex=True)\n",
    "axs[0, 0].set_title(\"x (model input)\")\n",
    "axs[0, 1].set_title(\"model prediction\")\n",
    "for i in range(n_steps):\n",
    "    axs[i, 0].imshow(torchvision.utils.make_grid(step_history[i])[0].clip(0, 1), cmap=\"Greys\")\n",
    "    axs[i, 1].imshow(torchvision.utils.make_grid(pred_output_history[i])[0].clip(0, 1), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cop-diffusion-04jlPuwc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
