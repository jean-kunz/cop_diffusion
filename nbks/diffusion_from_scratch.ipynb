{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp diff_scratch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "#from diffusers import DDPMScheduler, UNet2DModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from cop_diffusion.utils import save_model, load_model\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=\"mnist/\", train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Labels:\", y)\n",
    "plt.imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corruption process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.rand_like(x)\n",
    "amount = .2\n",
    "noisy_x = (1-amount)*x + amount*noise\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(15, 5))\n",
    "axs[0].set_title(\"X\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n",
    "\n",
    "axs[1].set_title(\"Amount of X\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(x*(1-amount))[0], cmap=\"Greys\")\n",
    "\n",
    "axs[2].set_title(\"1-amount of noise\")\n",
    "axs[2].imshow(torchvision.utils.make_grid(noise*amount)[0], cmap=\"Greys\")\n",
    "\n",
    "\n",
    "axs[3].set_title(\"Noisy image\")\n",
    "axs[3].imshow(torchvision.utils.make_grid(noisy_x)[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt(x, amount):\n",
    "    \"\"\"Corrupt the input `x` by mixing it with noise according to `amount`\"\"\"\n",
    "    noise = torch.rand_like(x)\n",
    "    amount = amount.view(-1, 1, 1, 1)  # Sort shape so broadcasting works\n",
    "    return x * (1 - amount) + noise * amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the input data\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 5))\n",
    "axs[0].set_title(\"Input data\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n",
    "\n",
    "# Adding noise\n",
    "amount = torch.linspace(0, 1, x.shape[0])\n",
    "print(amount)  # Left to right -> more corruption\n",
    "noised_x = corrupt(x, amount)\n",
    "\n",
    "# Plotting the noised version\n",
    "axs[1].set_title(\"Corrupted data (-- amount increases -->)\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(noised_x)[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to learn noise\n",
    "\n",
    "We’d like a model that takes in a 28px noisy images and outputs a prediction of the same shape.\n",
    "\n",
    "**UNet** consists of a ‘constricting path’ through which data is compressed down and an ‘expanding path’ through which it expands back up to the original dimension (similar to an autoencoder) but also features skip connections that allow for information and gradients to flow across at different levels.\n",
    "\n",
    "![UNET](../res/unet.png)\n",
    "\n",
    "\n",
    "### See convolution_101.ipynb for better understanding of convolutions\n",
    "\n",
    "![Convolution_101](./convolution_101.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUNet(nn.Module):\n",
    "    \"\"\"A minimal UNet implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "        self.down_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(in_channels, 32, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            ]\n",
    "        )\n",
    "        self.up_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(32, out_channels, kernel_size=5, padding=2),\n",
    "            ]\n",
    "        )\n",
    "        self.act = nn.SiLU()  # The activation function\n",
    "        self.downscale = nn.MaxPool2d(2)\n",
    "        self.upscale = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = []\n",
    "        for i, l in enumerate(self.down_layers):\n",
    "            x = self.act(l(x))  # Through the layer and the activation function\n",
    "            if i < 2:  # For all but the third (final) down layer:\n",
    "                h.append(x)  # Storing output for skip connection\n",
    "                x = self.downscale(x)  # Downscale ready for the next layer\n",
    "\n",
    "        for i, l in enumerate(self.up_layers):\n",
    "            if i > 0:  # For all except the first up layer\n",
    "                x = self.upscale(x)  # Upscale\n",
    "                x += h.pop()  # Fetching stored output (skip connection)\n",
    "            x = self.act(l(x))  # Through the layer and the activation function\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BasicUNet()\n",
    "#x = torch.rand(8, 1, 28, 28)\n",
    "ux = model(x)\n",
    "ic(ux.shape)\n",
    "plt.imshow(torchvision.utils.make_grid(ux)[0], cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channel(input, channel_nb:int=0, info=\"\"):\n",
    "    '''You must provide on image of shape (batch, channel, height, width)convolved on many channels'''\n",
    "    title = f\"channel {channel_nb}, info: {info}\"\n",
    "    img = input[channel_nb].cpu().detach().numpy()\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")  # Turn off axis labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=1\n",
    "out_channels=1\n",
    "ic(x.shape)\n",
    "c0 = nn.Conv2d(in_channels, 32, kernel_size=5, padding=2)(x)\n",
    "ic(c0.shape);\n",
    "downscale = nn.MaxPool2d(2)\n",
    "cd0 = downscale(c0)\n",
    "ic(cd0.shape)\n",
    "show_channel(cd0[0],channel_nb=0, info='conv 0 -> downscale' )\n",
    "show_channel(cd0[0],channel_nb=31, info='conv 0 -> downscale' )\n",
    "\n",
    "\n",
    "c1 = nn.Conv2d(32, 64, kernel_size=5, padding=2)(cd0)\n",
    "cd1 = downscale(c1)\n",
    "ic(cd1.shape)\n",
    "show_channel(cd1[0], channel_nb=63,info='conv 1 -> downscale' )\n",
    "\n",
    "# Decoding part\n",
    "upscale = nn.Upsample(scale_factor=2)\n",
    "u0 = upscale(cd1)\n",
    "ic(u0.shape)\n",
    "show_channel(u0[0],channel_nb=0, info='upscale')\n",
    "uc0 = nn.Conv2d(64, 64, kernel_size=5, padding=2)(u0)\n",
    "show_channel(uc0[:,0],channel_nb=0, info='upscale -> conv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the UNet model (DDPM)\n",
    "\n",
    "https://github.com/nickd16/Diffusion-Models-from-Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM_Scheduler(nn.Module):\n",
    "    def __init__(self, num_time_steps: int=1000):\n",
    "        super().__init__()\n",
    "        self.beta = torch.linspace(1e-4, 0.02, num_time_steps, requires_grad=False)\n",
    "        alpha = 1 - self.beta\n",
    "        self.alpha = torch.cumprod(alpha, dim=0).requires_grad_(False)\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.beta[t], self.alpha[t]\n",
    "\n",
    "scheduler = DDPM_Scheduler(num_time_steps=1000)\n",
    "ic(scheduler(999))\n",
    "ic(scheduler(0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_time_steps = 500\n",
    "scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
    "\n",
    "\n",
    "model_version = \"0.1\"\n",
    "model_name = \"mnist_ddpm\"\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "n_epoch = 20\n",
    "last_epoch = 0\n",
    "\n",
    "\n",
    "do_train:bool=True\n",
    "if do_train:\n",
    "    train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    if last_epoch > 0:\n",
    "        model = load_model(\n",
    "            model_name=model_name, model_version=model_version, iter=last_epoch\n",
    "        )\n",
    "        from_epoch_nb = last_epoch + 1\n",
    "    else:\n",
    "        model = BasicUNet().to(device)\n",
    "        from_epoch_nb = 0\n",
    "\n",
    "    writer = SummaryWriter(\n",
    "            f\"../runs/{model_name}_{model_version}/{datetime.now().strftime('%m-%d-%Y_%H:%M:%S')}\"\n",
    "        )\n",
    "    log_interval:int=50\n",
    "    # The training loop\n",
    "    criterion = nn.MSELoss(reduction='mean')\n",
    "    lr=2e-5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    nb_batches = len(train_dataloader)\n",
    "    with tqdm(\n",
    "        total=(n_epoch+1-from_epoch_nb) * nb_batches,\n",
    "        desc=f\"Training update\",\n",
    "        unit=\"batch\",\n",
    "    ) as pbar:\n",
    "        for epoch in range(from_epoch_nb, n_epoch+1):\n",
    "            total_loss = 0\n",
    "            for batch_nb, (x, y) in enumerate(train_dataloader):\n",
    "                x = x.to(device)\n",
    "                n,c,w,h = x.shape\n",
    "                # we may exhaust the loader and have a smaller batch\n",
    "                t = torch.randint(0, num_time_steps,(n,))\n",
    "                noise = torch.randn_like(x, requires_grad=False)\n",
    "\n",
    "                a = scheduler.alpha[t].view(n,1,1,1).to(device)\n",
    "                #ic(t.shape, e.shape, a.shape)\n",
    "                x = (torch.sqrt(a)*x) + (torch.sqrt(1-a)*noise)\n",
    "\n",
    "                output = model(x)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(output, noise)\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                i = (epoch*nb_batches) + batch_nb\n",
    "                writer.add_scalar(f\"train loss\", loss.item(), (epoch*nb_batches) + batch_nb)\n",
    "                if i % log_interval == 0:\n",
    "                    for name, kernel_weight in model.named_parameters():\n",
    "                        writer.add_histogram(name, kernel_weight,i )\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_nb\": batch_nb,\n",
    "                        #\"train_loss\": f\"{loss.item():.4f}\",\n",
    "                    })\n",
    "                ...\n",
    "        save_model(model=model, model_name=model_name, model_version=model_version, iter=epoch)\n",
    "else:\n",
    "    model = load_model(model_name=model_name, model_version=model_version, iter=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_reverse(images: list):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(10,1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        x = images[i].squeeze(0)\n",
    "        x = torch.rearrange(x, 'c h w -> h w c')\n",
    "        x = x.numpy()\n",
    "        ax.imshow(x)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "scheduler = DDPM_Scheduler(num_time_steps=num_time_steps)\n",
    "times = [0,15,50,100,200,300,400,550,700,999]\n",
    "images = []\n",
    "with torch.no_grad():\n",
    "    model = model.eval()\n",
    "    for i in range(10):\n",
    "        z = torch.randn(1, 1, 32, 32)\n",
    "        for t in reversed(range(1, num_time_steps)):\n",
    "            t = [t]\n",
    "            temp = (scheduler.beta[t]/( (torch.sqrt(1-scheduler.alpha[t]))*(torch.sqrt(1-scheduler.beta[t])) ))\n",
    "            z = (1/(torch.sqrt(1-scheduler.beta[t])))*z - (temp*model(z.to(device)).cpu())\n",
    "            if t[0] in times:\n",
    "                images.append(z)\n",
    "            e = torch.randn(1, 1, 32, 32)\n",
    "            z = z + (e*torch.sqrt(scheduler.beta[t]))\n",
    "        temp = scheduler.beta[0]/( (torch.sqrt(1-scheduler.alpha[0]))*(torch.sqrt(1-scheduler.beta[0])) )\n",
    "        x = (1/(torch.sqrt(1-scheduler.beta[0])))*z - (temp*model(z.to(device),[0]).cpu())\n",
    "\n",
    "        images.append(x)\n",
    "        x = torch.rearrange(x.squeeze(0), 'c h w -> h w c').detach()\n",
    "        x = x.numpy()\n",
    "        plt.imshow(x)\n",
    "        plt.show()\n",
    "        display_reverse(images)\n",
    "        images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the UNet model\n",
    "\n",
    "Difference with DDPM method.\n",
    "\n",
    "The training objective is different, involving predicting the noise rather than the denoised image\n",
    "\n",
    "The model is conditioned on the amount of noise present via timestep conditioning, where t is passed as an additional argument to the forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"0.1\"\n",
    "model_name = \"mnist_diffus\"\n",
    "\n",
    "\n",
    "# Dataloader (you can mess with batch size)\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# How many runs through the data should we do?\n",
    "n_epoch = 3\n",
    "\n",
    "# Create the network\n",
    "model = BasicUNet()\n",
    "model.to(device)\n",
    "\n",
    "# Our loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# The optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses = []\n",
    "\n",
    "do_train: bool = True\n",
    "last_update_epoch = 0\n",
    "\n",
    "if do_train:\n",
    "    writer = SummaryWriter(\n",
    "        f\"../runs/{model_name}_{model_version}/{datetime.now().strftime('%m-%d-%Y_%H:%M:%S')}\"\n",
    "    )\n",
    "    # The training loop\n",
    "    nb_batches = len(train_dataloader)\n",
    "    with tqdm(\n",
    "        total=n_epoch * nb_batches,\n",
    "        desc=f\"Training update\",\n",
    "        unit=\"batch\",\n",
    "    ) as pbar:\n",
    "        for epoch in range(n_epoch):\n",
    "            for batch_nb, (x, y) in enumerate(train_dataloader):\n",
    "                # Get some data and prepare the corrupted version\n",
    "                x = x.to(device)  # Data on the GPU\n",
    "                noise_amount = torch.rand(x.shape[0]).to(\n",
    "                    device\n",
    "                )  # Pick random noise amounts\n",
    "                noisy_x = corrupt(x, noise_amount)  # Create our noisy x\n",
    "\n",
    "                # Get the model prediction\n",
    "                pred = model(noisy_x)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss = loss_fn(\n",
    "                    pred, x\n",
    "                )  # How close is the output to the true 'clean' x?\n",
    "\n",
    "                # Backprop and update the params:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                # Store the loss for later\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_nb\": batch_nb,\n",
    "                        \"train_loss\": f\"{loss.item():.4f}\",\n",
    "                    }\n",
    "                )\n",
    "                writer.add_scalar(f\"train loss\", loss.item(), (epoch*nb_batches) + batch_nb)\n",
    "\n",
    "            for name, kernel_weight in model.named_parameters():\n",
    "                writer.add_histogram(name, kernel_weight, epoch)\n",
    "\n",
    "            # Print our the average of the loss values for this epoch:\n",
    "            avg_loss = sum(losses[nb_batches :]) / nb_batches\n",
    "            # print(f\"Finished epoch {epoch}. Average loss for this epoch: {avg_loss:05f}\")\n",
    "\n",
    "    # View the loss curve\n",
    "    plt.plot(losses)\n",
    "    plt.ylim(0, 0.25)\n",
    "\n",
    "\n",
    "    save_model(model=model, model_name=model_name, model_version=model_version, iter=epoch)\n",
    "else:\n",
    "    model = load_model(model_name=model_name, model_version=model_version, iter=last_update_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction without any noise added.\n",
    "\n",
    "dl = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(dl))\n",
    "with torch.no_grad():\n",
    "    ux = model(x.to(device))\n",
    "    ic(ux.shape)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 5))\n",
    "axs[0].set_title(\"Input\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n",
    "axs[1].set_title(\"Reconstructed\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(ux.cpu())[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrupt with a range of amounts\n",
    "amount = torch.linspace(0, 1, x.shape[0])  # Left to right -> more corruption\n",
    "noised_x = corrupt(x, amount)\n",
    "\n",
    "# Get the model predictions\n",
    "with torch.no_grad():\n",
    "    preds = model(noised_x.to(device)).detach().cpu()\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 7))\n",
    "axs[0].set_title(\"Input data\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0].clip(0, 1), cmap=\"Greys\")\n",
    "axs[1].set_title(\"Corrupted data\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(noised_x)[0].clip(0, 1), cmap=\"Greys\")\n",
    "axs[2].set_title(\"Network Predictions\")\n",
    "axs[2].imshow(torchvision.utils.make_grid(preds)[0].clip(0, 1), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Sampling strategy: Break the process into 5 steps and move 1/5'th of the way there each time:\n",
    "n_steps = 5\n",
    "x = torch.rand(8, 1, 28, 28).to(device)  # Start from random\n",
    "step_history = [x.detach().cpu()]\n",
    "pred_output_history = []\n",
    "\n",
    "for i in range(n_steps):\n",
    "    with torch.no_grad():  # No need to track gradients during inference\n",
    "        pred = model(x)  # Predict the denoised x0\n",
    "    pred_output_history.append(pred.detach().cpu())  # Store model output for plotting\n",
    "    mix_factor = 1 / (n_steps - i)  # How much we move towards the prediction\n",
    "    x = x * (1 - mix_factor) + pred * mix_factor  # Move part of the way there\n",
    "    step_history.append(x.detach().cpu())  # Store step for plotting\n",
    "\n",
    "fig, axs = plt.subplots(n_steps, 2, figsize=(9, 4), sharex=True)\n",
    "axs[0, 0].set_title(\"x (model input)\")\n",
    "axs[0, 1].set_title(\"model prediction\")\n",
    "for i in range(n_steps):\n",
    "    axs[i, 0].imshow(torchvision.utils.make_grid(step_history[i])[0].clip(0, 1), cmap=\"Greys\")\n",
    "    axs[i, 1].imshow(torchvision.utils.make_grid(pred_output_history[i])[0].clip(0, 1), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cop-diffusion-04jlPuwc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
