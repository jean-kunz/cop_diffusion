{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp diff_scratch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env PYDEVD_DISABLE_FILE_VALIDATION=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "import math\n",
    "#from diffusers import DDPMScheduler, UNet2DModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from cop_diffusion.utils import save_model, load_model\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"mnist/\", train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(train_dataloader))\n",
    "oh_y = torch.nn.functional.one_hot(y)\n",
    "ic(\"Input shape:\", x.shape)\n",
    "ic(\"Labels:\", y)\n",
    "plt.imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corruption process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "amount = torch.linspace(0, 1, x.shape[0])\n",
    "amount = amount.view(-1, 1, 1, 1)\n",
    "noise = torch.rand_like(x)\n",
    "x_noisy = (1-amount)*x + amount*noise\n",
    "\n",
    "ic(amount.squeeze())\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(50, 5))\n",
    "axs[0].set_title(\"100% of X\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n",
    "\n",
    "axs[1].set_title(f\"1-Amount  of X\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(x*(1-amount))[0], cmap=\"Greys\")\n",
    "\n",
    "axs[2].set_title(f\"Amount  of noise\")\n",
    "axs[2].imshow(torchvision.utils.make_grid(noise*amount)[0], cmap=\"Greys\")\n",
    "\n",
    "\n",
    "axs[3].set_title(f\"Noisy image: 1- amount of x, amount of noise\")\n",
    "axs[3].imshow(torchvision.utils.make_grid(x_noisy)[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise scheduling\n",
    "\n",
    "- Beta $\\beta$, control the noise added at each step. Beta is the noise schedule, the variance of noised added (between 0..1) at each t\n",
    "- Alpha $\\alpha$, control the noise removed at each step $\\alpha_t = 1-\\beta_t$. This is the **signal retention** \n",
    "\n",
    "Choosing the beta schedule is key in the process. It can be\n",
    "- linear: increase linearly over timestep\n",
    "- cosine: follow a cosine function, start slowly, increase rapidly, slow down again. Often better perf. \n",
    "- quadratic or other non linear schedules. \n",
    "\n",
    "#### Forward\n",
    "\n",
    "Gradually add noise to image over serie of timesteps \n",
    "$x_t = \\sqrt{\\alpha_{\\text{cumprod}t}} \\cdot x_0 + \\sqrt{1 - \\alpha{\\text{cumprod}_t}} \\cdot \\epsilon$\n",
    "\n",
    "- $\\epsilon$ : the gaussian noise\n",
    "- $x_0$: original image\n",
    "- $\\alpha = 1 - \\beta $\n",
    "- $\\alpha_{cumprod_t}$ cumulative product up to time step t. Represent how much of the original image remains after t steps.\n",
    "\n",
    "\n",
    "#### Reverse diffusion (Denoising)\n",
    "\n",
    "To reverse diffusion we could do it in 2 different ways:\n",
    "\n",
    "a. Estimate directly $x_0$ from predicted noise\n",
    "\n",
    "Estimate what a clean desk would be without the mess. Mentally subtract the mess. So we directly estimate the original image from the noisy one at timestep t. In diffusion model, we don't use it. \n",
    "$\\hat{x}0 = \\frac{x_t - \\sqrt{1 - \\alpha{\\text{cumprod}t}} \\cdot \\epsilon{\\theta}(x_t, t)}{\\sqrt{\\alpha_{\\text{cumprod}_t}}}$\n",
    "\n",
    "- $\\epsilon{\\theta}(x_t,t)$: the model prediction of the noise added at timestep t\n",
    "- $\\alpha{\\text{cumprod}t}$: how much of the original signal remains. \n",
    " \n",
    "\n",
    "b. Iterate\n",
    "\n",
    "Transition to a less messy desk, by using smooth transitions. \n",
    "Iteratively remove the noise added in forward process to reconstruct original image from noisy image. Trained model predict the noise.\n",
    "\n",
    "It incorporate posterior variance randomness that prevent exact reconstruction and avoid collapse. \n",
    "\n",
    "$x_{t-1} = \\sqrt{\\frac{1}{\\alpha_t}} \\left( x_t - \\frac{\\beta_t}{\\sqrt{1 - \\alpha_{\\text{cumprod}t}}} \\cdot \\epsilon{\\theta}(x_t, t) \\right) + \\sqrt{\\beta_t} \\cdot \\epsilon$\n",
    "\n",
    "- $\\epsilon$ is some random noise added.\n",
    "\n",
    "##### Why directly estimating $x_0$ isn't used\n",
    "\n",
    "it would require the model to  handle a wider range of outputs, increasig complexity and variablity. With iterative noise prediction, the output space is consistent and simpler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPMScheduler(nn.Module):\n",
    "    def __init__(self, num_time_steps: int=1000, beta_start:float=1e-4, beta_end:float=0.02, device:str='cpu'):\n",
    "        super().__init__()\n",
    "        self.num_time_steps = num_time_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.device = device\n",
    "\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_time_steps, requires_grad=False).to(device)\n",
    "        self.alphas = 1 - self.betas\n",
    "        # cumulative product of alphas upto time t, quantiies the amount of info retained at time t in the forward diffusion process\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0).requires_grad_(False)\n",
    "        # special case: t=0, no previous timestep\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0]).to(device), self.alphas_cumprod[:-1]]).requires_grad_(False)\n",
    "        self.sqrt_alpha_cumprod = torch.sqrt(self.alphas_cumprod).to(device)\n",
    "        self.sqrt_one_minus_alpha_cumprod = torch.sqrt(1.0 - self.alphas_cumprod).to(device)\n",
    "        self.sqrt_reciprocal_alphas = torch.sqrt(1.0 / self.alphas).to(device)\n",
    "\n",
    "        self.posterior_variance = self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "\n",
    "    def add_noise_step(self, x, t) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Gradually add noise to the image\n",
    "        \"\"\"\n",
    "        sqrt_alpha_cum_prod_t = self.sqrt_alpha_cumprod[t].view(-1,1,1,1)\n",
    "        sqrt_one_minus_alpha_cum_prod_t = self.sqrt_one_minus_alpha_cumprod[t].view(-1,1,1,1)\n",
    "        noise = torch.randn_like(x).to(self.device)\n",
    "        noisy_x = sqrt_alpha_cum_prod_t * x + sqrt_one_minus_alpha_cum_prod_t * noise\n",
    "        return noisy_x, noise\n",
    "\n",
    "    def denoise_step(self, pred_noise, x_noisy, t):\n",
    "        \"\"\" estimage previous image $x_{t-1}$\n",
    "        As it incorporate posterior variance, randomnsess that prevent exact reconstruction.\n",
    "        \"\"\"\n",
    "\n",
    "        # we get value at time t\n",
    "        sqrt_reciprocal_alpha_t = self.sqrt_reciprocal_alphas[t].view(-1,1,1,1)\n",
    "        sqrt_one_minus_alpha_cum_prod_t = self.sqrt_one_minus_alpha_cumprod[t].view(-1,1,1,1)\n",
    "        beta_t = self.betas[t].view(-1,1,1,1)\n",
    "        posterior_variance_t = self.posterior_variance[t].view(-1,1,1,1)\n",
    "\n",
    "        # Compute the mean of the posterior q(x_{t-1} | x_t, x_0)\n",
    "        # Using the DDPM reverse process mean formula\n",
    "        pred_mean = sqrt_reciprocal_alpha_t * (x_noisy * beta_t * pred_noise) / sqrt_one_minus_alpha_cum_prod_t\n",
    "\n",
    "        # sample noise for the next step to avoid collaps of model.\n",
    "        z = torch.randn_like(x_noisy).to(self.device)\n",
    "        x_prev = pred_mean + torch.sqrt(posterior_variance_t)* z\n",
    "        return x_prev\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scheduler = DDPMScheduler(num_time_steps=500, device=device)\n",
    "\n",
    "t = torch.tensor([0,50, 100, 150, 200,300,400,499]).to(device)\n",
    "assert t.shape[0]==x.shape[0], \"it should be the same nb of examples\"\n",
    "x = x.to(device)\n",
    "x_noisy, noise = scheduler.add_noise_step(x, t)\n",
    "ic(x_noisy.shape, noise.shape)\n",
    "plt.imshow(torchvision.utils.make_grid(x.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(torchvision.utils.make_grid(x_noisy.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "\n",
    "denoised_x = scheduler.denoise_step(noise, x_noisy, t)\n",
    "plt.imshow(torchvision.utils.make_grid(denoised_x.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to learn noise\n",
    "\n",
    "We’d like a model that takes in a 28px noisy images and outputs a prediction of the same shape.\n",
    "\n",
    "**UNet** consists of a ‘constricting path’ through which data is compressed down and an ‘expanding path’ through which it expands back up to the original dimension (similar to an autoencoder) but also features skip connections that allow for information and gradients to flow across at different levels.\n",
    "\n",
    "![UNET](../res/unet.png)\n",
    "\n",
    "\n",
    "### See convolution_101.ipynb for better understanding of convolutions\n",
    "\n",
    "![Convolution_101](./convolution_101.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_timesteps=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Create a matrix of [max_timesteps, embedding_dim] with positional encodings\n",
    "        pe = torch.zeros(max_timesteps, embedding_dim)\n",
    "        position = torch.arange(0, max_timesteps, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.0) / embedding_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            t: Tensor of shape (batch_size,) containing timesteps.\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, embedding_dim).\n",
    "        \"\"\"\n",
    "        return self.pe[t].squeeze(1)\n",
    "\n",
    "class SimpleDiffusionModel(nn.Module):\n",
    "    def __init__(self, ctx_nb_feats=10, embedding_dim=128):\n",
    "        super(SimpleDiffusionModel, self).__init__()\n",
    "        self.ctx_nb_feats = ctx_nb_feats\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Embedding for digit labels\n",
    "        self.label_embedding = nn.Embedding(ctx_nb_feats, embedding_dim)\n",
    "\n",
    "        # Positional encoding for timesteps\n",
    "        # TODO try with learned embeddings\n",
    "        self.time_embedding = PositionalEncoding(embedding_dim)\n",
    "\n",
    "        # Fully connected layer to project combined embeddings\n",
    "        self.fc1 = nn.Linear(embedding_dim, 64 * 28 * 28)\n",
    "\n",
    "        # Convolutional layers for the U-Net architecture\n",
    "        self.conv1 = nn.Conv2d(1 + 64, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, t, c):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Noisy image tensor of shape (batch_size, 1, 28, 28)\n",
    "            t: Timestep tensor of shape (batch_size,)\n",
    "            labels: Digit labels tensor of shape (batch_size,)\n",
    "        Returns:\n",
    "            Predicted noise tensor of shape (batch_size, 1, 28, 28)\n",
    "        \"\"\"\n",
    "        # Embed labels\n",
    "        label_emb = self.label_embedding(c)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Embed timesteps\n",
    "        time_emb = self.time_embedding(t)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Combine label and time embeddings\n",
    "        combined_emb = label_emb + time_emb  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Project combined embeddings to match image dimensions\n",
    "        emb_proj = self.fc1(combined_emb)  # (batch_size, 64*28*28)\n",
    "        emb_proj = emb_proj.view(-1, 64, 28, 28)  # (batch_size, 64, 28, 28)\n",
    "\n",
    "        # Concatenate embeddings with the input image\n",
    "        x = torch.cat([x, emb_proj], dim=1)  # (batch_size, 1+64, 28, 28)\n",
    "\n",
    "        # Pass through convolutional layers with ReLU activations\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.conv4(x)  # No activation on the output\n",
    "\n",
    "        return x  # Predicted noise\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(train_dataloader))\n",
    "model = SimpleDiffusionModel(ctx_nb_feats=9).to(device)\n",
    "#x = torch.rand(8, 1, 28, 28)\n",
    "t = torch.zeros(x.shape[0]).long().to(device)\n",
    "#oh_y = oh_y.to(device)\n",
    "x = x.to(device)\n",
    "y = y.long().to(device)\n",
    "ic(t.shape, y.shape)\n",
    "ux = model(x,t, y)\n",
    "ic(ux.shape, x.shape)\n",
    "ic(torchvision.utils.make_grid(x.cpu())[0].shape)\n",
    "plt.imshow(torchvision.utils.make_grid(x.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "plt.imshow(torchvision.utils.make_grid(ux.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channel(input, channel_nb:int=0, info=\"\"):\n",
    "    '''You must provide on image of shape (batch, channel, height, width)convolved on many channels'''\n",
    "    title = f\"channel {channel_nb}, info: {info}\"\n",
    "    img = input[channel_nb].cpu().detach().numpy()\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")  # Turn off axis labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=1\n",
    "out_channels=1\n",
    "ic(x.shape)\n",
    "c0 = nn.Conv2d(in_channels, 32, kernel_size=5, padding=2).to(device)(x)\n",
    "ic(c0.shape);\n",
    "downscale = nn.MaxPool2d(2).to(device)\n",
    "cd0 = downscale(c0)\n",
    "ic(cd0.shape)\n",
    "show_channel(cd0[0],channel_nb=0, info='conv 0 -> downscale' )\n",
    "show_channel(cd0[0],channel_nb=31, info='conv 0 -> downscale' )\n",
    "\n",
    "\n",
    "c1 = nn.Conv2d(32, 64, kernel_size=5, padding=2).to(device)(cd0)\n",
    "cd1 = downscale(c1)\n",
    "ic(cd1.shape)\n",
    "show_channel(cd1[0], channel_nb=63,info='conv 1 -> downscale' )\n",
    "\n",
    "# Decoding part\n",
    "upscale = nn.Upsample(scale_factor=2).to(device)\n",
    "u0 = upscale(cd1)\n",
    "ic(u0.shape)\n",
    "show_channel(u0[0],channel_nb=0, info='upscale')\n",
    "uc0 = nn.Conv2d(64, 64, kernel_size=5, padding=2).to(device)(u0)\n",
    "show_channel(uc0[:,0],channel_nb=0, info='upscale -> conv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the UNet model (DDPM)\n",
    "\n",
    "https://github.com/nickd16/Diffusion-Models-from-Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_norm(model) -> float:\n",
    "    total_norm = 0.0\n",
    "    for param in model.parameters():\n",
    "        if param.grad is not None:\n",
    "            param_norm = param.grad.data.norm(2)  # Compute L2 norm of gradients\n",
    "            total_norm += param_norm.item() ** 2  # Square the norms and accumulate\n",
    "\n",
    "    total_norm = total_norm ** 0.5\n",
    "    return total_norm\n",
    "\n",
    "compute_grad_norm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "num_time_steps = 500\n",
    "scheduler = DDPMScheduler(num_time_steps=num_time_steps, device=device)\n",
    "# as alpha and beta are not learned nn.parameters they are not moved to device, if you do scheduler.to(device)\n",
    "scheduler.betas = scheduler.betas.to(device)\n",
    "scheduler.alphas_cumprod = scheduler.alphas_cumprod.to(device)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "use_tiny_dataset = False\n",
    "do_train:bool=True\n",
    "if use_tiny_dataset:\n",
    "    n_epoch = 20\n",
    "else:\n",
    "    n_epoch = 7\n",
    "    last_epoch = 0\n",
    "\n",
    "model_version = \"0.2\"\n",
    "model_name = f\"mnist_{'tiny_' if use_tiny_dataset else ''}ddpm_time_emb\"\n",
    "model_name = f\"mnist_{'tiny_' if use_tiny_dataset else ''}SimpleDiffusionModel\"\n",
    "\n",
    "if do_train:\n",
    "    if use_tiny_dataset:\n",
    "        # create a very tiny dataset to overfit the training and validate the model has enough capacity to have a loss of 0.\n",
    "        random_indices = torch.randperm(len(train_dataset))[:10]\n",
    "        train_tiny_dataset = Subset(train_dataset, random_indices)\n",
    "        train_dataloader = DataLoader(train_tiny_dataset, batch_size=5, shuffle=True)\n",
    "    else:\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    if last_epoch > 0:\n",
    "        model = load_model(\n",
    "            model_name=model_name, model_version=model_version, iter=last_epoch\n",
    "        )\n",
    "        from_epoch_nb = last_epoch + 1\n",
    "    else:\n",
    "\n",
    "        #model = BasicUNet(ctx_nb_feats=9).to(device)\n",
    "        model = SimpleDiffusionModel(ctx_nb_feats=9).to(device)\n",
    "        from_epoch_nb = 0\n",
    "\n",
    "    writer = SummaryWriter(\n",
    "            f\"../runs/{model_name}_{model_version}/{datetime.now().strftime('%m-%d-%Y_%H:%M:%S')}\"\n",
    "        )\n",
    "    log_interval:int=50\n",
    "    # The training loop\n",
    "    criterion = nn.MSELoss(reduction='mean')#.to(device)\n",
    "    lr=2e-5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    nb_batches = len(train_dataloader)\n",
    "    with tqdm(\n",
    "        total=(n_epoch+1-from_epoch_nb) * nb_batches,\n",
    "        desc=f\"Training update\",\n",
    "        unit=\"batch\",\n",
    "    ) as pbar:\n",
    "        grad_norms = []\n",
    "        for epoch in range(from_epoch_nb, n_epoch+1):\n",
    "            total_loss = 0\n",
    "            for batch_nb, (x, y) in enumerate(train_dataloader):\n",
    "                x = x.to(device)\n",
    "                y = y.long().to(device)\n",
    "\n",
    "                b = x.size(0)\n",
    "                t = torch.randint(0, num_time_steps,(b,)).to(device)\n",
    "                x_noisy, noise  = scheduler.add_noise_step(x,t )\n",
    "                x_noisy= x_noisy.to(device)\n",
    "\n",
    "                # we may exhaust the loader and have a smaller batch\n",
    "                output = model(x_noisy,t,y)\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(output, noise)\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                i = (epoch*nb_batches) + batch_nb\n",
    "                writer.add_scalar(f\"train loss\", loss.item(), (epoch*nb_batches) + batch_nb)\n",
    "                if i % log_interval == 0:\n",
    "                    for name, kernel_weight in model.named_parameters():\n",
    "                        if kernel_weight.numel() > 0:\n",
    "                            writer.add_histogram(name, kernel_weight, i)\n",
    "\n",
    "                    # compute gradient norm\n",
    "                    grad_norm = compute_grad_norm(model)\n",
    "                    grad_norms.append(grad_norm)\n",
    "                    writer.add_histogram(\"grad norm\", grad_norm, i)\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_nb\": batch_nb,\n",
    "                        \"train_loss\": f\"{loss.item():.4f}\",\n",
    "                    })\n",
    "                ...\n",
    "        if not use_tiny_dataset:\n",
    "            save_model(model=model, model_name=model_name, model_version=model_version, iter=epoch)\n",
    "else:\n",
    "    if not use_tiny_dataset:\n",
    "        model = load_model(model_name=model_name, model_version=model_version, iter=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "# plot in tensorboard.\n",
    "plt.figure(figsize=(20, 4))\n",
    "legends = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        g = param.grad\n",
    "        m_g = g.mean()\n",
    "        std_g = g.std()\n",
    "        hy, hx = torch.histogram(g, density=True)\n",
    "        plt.plot(hx[:-1].cpu().detach(), hy.cpu().detach())\n",
    "        legends.append(f\"layer {name}\")\n",
    "\n",
    "plt.legend(legends)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "- it look loss get to 0.45 after 10 epochs and stay there\n",
    "- with this model with a tiny dataset (10 examples) it cannot go lower than 0.45 after 1000 or 5000 epochs\n",
    "- Enhance the model by adding capacity and by checking it overfit to 0 loss with a very small dataset (like 5 samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 5\n",
    "h,w = 28,28\n",
    "\n",
    "def show_images(imgs_tensor):\n",
    "    grid =torchvision.utils.make_grid(imgs_tensor.cpu())\n",
    "    plt.imshow(grid.permute(1, 2, 0)[:,:,0], cmap=\"Greys\")\n",
    "    plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "    ctx = torch.tensor([0,1,2,3,4]).to(device)\n",
    "    samples = torch.randn(n_sample,1,h,w).to(device)\n",
    "    ic(samples.size())\n",
    "    with tqdm(\n",
    "        total=num_time_steps,\n",
    "        desc=f\"Denoise\",\n",
    "        unit=\"timestep\",\n",
    "    ) as pbar:\n",
    "        for i in range(num_time_steps, 0,-1):\n",
    "            t = torch.tensor([i]*n_sample).to(device)\n",
    "            pred_noise = model(samples,t,ctx)\n",
    "            samples = scheduler.denoise_step(pred_noise=pred_noise, x_noisy=samples,t=t)\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\n",
    "                        \"timestep\": i,\n",
    "                    })\n",
    "\n",
    "            if 6>i or i >495:\n",
    "                show_images(pred_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    for i in range(n_sample, 0, -1):\n",
    "        t = torch.randint(i, num_time_steps,(b,)).to(device)\n",
    "        ctx = torch.tensor([1]).to(device)\n",
    "\n",
    "        pred_noise = model(samples, t, ctx)\n",
    "        pred_noise(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_reverse(images: list):\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(10,1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        x = images[i].squeeze(0)\n",
    "        #x = torch.rearrange(x, 'c h w -> h w c')\n",
    "        x = x.permute(1,2,0)\n",
    "        x = x.numpy()\n",
    "        ax.imshow(x)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "scheduler = DDPMScheduler(num_time_steps=num_time_steps)\n",
    "times = [0,15,50,100,200,300,400,499]\n",
    "images = []\n",
    "with torch.no_grad():\n",
    "    model = model.eval()\n",
    "    for i in range(10):\n",
    "        z = torch.randn(1, 1, 32, 32)\n",
    "        for t in reversed(range(1, num_time_steps)):\n",
    "            t = [t]\n",
    "            temp = (scheduler.betas[t]/( (torch.sqrt(1-scheduler.alphas_cumprod[t]))*(torch.sqrt(1-scheduler.betas[t])) ))\n",
    "            z = (1/(torch.sqrt(1-scheduler.betas[t])))*z - (temp*model(z.to(device),t=[0]).cpu())\n",
    "            if t[0] in times:\n",
    "                images.append(z)\n",
    "            e = torch.randn(1, 1, 32, 32)\n",
    "            z = z + (e*torch.sqrt(scheduler.betas[t]))\n",
    "        temp = scheduler.betas[0]/( (torch.sqrt(1-scheduler.alphas_cumprod[0]))*(torch.sqrt(1-scheduler.betas[0])) )\n",
    "        y = torch.randint(0,9,(1,1)).to(device)\n",
    "        z_pred =model(z.to(device),t=[0],c=y)\n",
    "        ic(z_pred.shape)\n",
    "        x = (1/(torch.sqrt(1-scheduler.betas[0])))*z - (temp*z_pred.cpu())\n",
    "\n",
    "        images.append(x)\n",
    "        #x = torch.rearrange(x.squeeze(0), 'c h w -> h w c').detach()\n",
    "        ic(x.shape, x.squeeze(0).shape)\n",
    "        x = x.squeeze(0).permute( 1,2,0).detach()\n",
    "        x = x.numpy()\n",
    "        plt.imshow(x)\n",
    "        plt.show()\n",
    "        display_reverse(images)\n",
    "        images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the UNet model\n",
    "\n",
    "Difference with DDPM method.\n",
    "\n",
    "The training objective is different, involving predicting the noise rather than the denoised image\n",
    "\n",
    "The model is conditioned on the amount of noise present via timestep conditioning, where t is passed as an additional argument to the forward method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = \"0.1\"\n",
    "model_name = \"mnist_diffus\"\n",
    "\n",
    "\n",
    "# Dataloader (you can mess with batch size)\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# How many runs through the data should we do?\n",
    "n_epoch = 3\n",
    "\n",
    "# Create the network\n",
    "model = BasicUNet()\n",
    "model.to(device)\n",
    "\n",
    "# Our loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# The optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Keeping a record of the losses for later viewing\n",
    "losses = []\n",
    "\n",
    "do_train: bool = True\n",
    "last_update_epoch = 0\n",
    "\n",
    "if do_train:\n",
    "    writer = SummaryWriter(\n",
    "        f\"../runs/{model_name}_{model_version}/{datetime.now().strftime('%m-%d-%Y_%H:%M:%S')}\"\n",
    "    )\n",
    "    # The training loop\n",
    "    nb_batches = len(train_dataloader)\n",
    "    with tqdm(\n",
    "        total=n_epoch * nb_batches,\n",
    "        desc=f\"Training update\",\n",
    "        unit=\"batch\",\n",
    "    ) as pbar:\n",
    "        for epoch in range(n_epoch):\n",
    "            for batch_nb, (x, y) in enumerate(train_dataloader):\n",
    "                # Get some data and prepare the corrupted version\n",
    "                x = x.to(device)  # Data on the GPU\n",
    "                noise_amount = torch.rand(x.shape[0]).to(\n",
    "                    device\n",
    "                )  # Pick random noise amounts\n",
    "                x_noisy = corrupt(x, noise_amount)  # Create our noisy x\n",
    "\n",
    "                # Get the model prediction\n",
    "                pred = model(x_noisy)\n",
    "\n",
    "                # Calculate the loss\n",
    "                loss = loss_fn(\n",
    "                    pred, x\n",
    "                )  # How close is the output to the true 'clean' x?\n",
    "\n",
    "                # Backprop and update the params:\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                # Store the loss for later\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"batch_nb\": batch_nb,\n",
    "                        \"train_loss\": f\"{loss.item():.4f}\",\n",
    "                    }\n",
    "                )\n",
    "                writer.add_scalar(f\"train loss\", loss.item(), (epoch*nb_batches) + batch_nb)\n",
    "\n",
    "            for name, kernel_weight in model.named_parameters():\n",
    "                writer.add_histogram(name, kernel_weight, epoch)\n",
    "\n",
    "            # Print our the average of the loss values for this epoch:\n",
    "            avg_loss = sum(losses[nb_batches :]) / nb_batches\n",
    "            # print(f\"Finished epoch {epoch}. Average loss for this epoch: {avg_loss:05f}\")\n",
    "\n",
    "    # View the loss curve\n",
    "    plt.plot(losses)\n",
    "    plt.ylim(0, 0.25)\n",
    "\n",
    "\n",
    "    save_model(model=model, model_name=model_name, model_version=model_version, iter=epoch)\n",
    "else:\n",
    "    model = load_model(model_name=model_name, model_version=model_version, iter=last_update_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction without any noise added.\n",
    "\n",
    "dl = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(dl))\n",
    "with torch.no_grad():\n",
    "    ux = model(x.to(device))\n",
    "    ic(ux.shape)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 5))\n",
    "axs[0].set_title(\"Input\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n",
    "axs[1].set_title(\"Reconstructed\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(ux.cpu())[0], cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrupt with a range of amounts\n",
    "amount = torch.linspace(0, 1, x.shape[0])  # Left to right -> more corruption\n",
    "noised_x = corrupt(x, amount)\n",
    "\n",
    "# Get the model predictions\n",
    "with torch.no_grad():\n",
    "    preds = model(noised_x.to(device)).detach().cpu()\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 7))\n",
    "axs[0].set_title(\"Input data\")\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0].clip(0, 1), cmap=\"Greys\")\n",
    "axs[1].set_title(\"Corrupted data\")\n",
    "axs[1].imshow(torchvision.utils.make_grid(noised_x)[0].clip(0, 1), cmap=\"Greys\")\n",
    "axs[2].set_title(\"Network Predictions\")\n",
    "axs[2].imshow(torchvision.utils.make_grid(preds)[0].clip(0, 1), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Sampling strategy: Break the process into 5 steps and move 1/5'th of the way there each time:\n",
    "n_steps = 5\n",
    "x = torch.rand(8, 1, 28, 28).to(device)  # Start from random\n",
    "step_history = [x.detach().cpu()]\n",
    "pred_output_history = []\n",
    "\n",
    "for i in range(n_steps):\n",
    "    with torch.no_grad():  # No need to track gradients during inference\n",
    "        pred = model(x)  # Predict the denoised x0\n",
    "    pred_output_history.append(pred.detach().cpu())  # Store model output for plotting\n",
    "    mix_factor = 1 / (n_steps - i)  # How much we move towards the prediction\n",
    "    x = x * (1 - mix_factor) + pred * mix_factor  # Move part of the way there\n",
    "    step_history.append(x.detach().cpu())  # Store step for plotting\n",
    "\n",
    "fig, axs = plt.subplots(n_steps, 2, figsize=(9, 4), sharex=True)\n",
    "axs[0, 0].set_title(\"x (model input)\")\n",
    "axs[0, 1].set_title(\"model prediction\")\n",
    "for i in range(n_steps):\n",
    "    axs[i, 0].imshow(torchvision.utils.make_grid(step_history[i])[0].clip(0, 1), cmap=\"Greys\")\n",
    "    axs[i, 1].imshow(torchvision.utils.make_grid(pred_output_history[i])[0].clip(0, 1), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cop-diffusion-04jlPuwc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
