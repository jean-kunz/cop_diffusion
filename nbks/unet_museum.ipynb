{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%env PYDEVD_DISABLE_FILE_VALIDATION=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "import math\n",
    "#from diffusers import DDPMScheduler, UNet2DModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from cop_diffusion.utils import save_model, load_model\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"mnist/\", train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(train_dataloader))\n",
    "oh_y = torch.nn.functional.one_hot(y)\n",
    "ic(\"Input shape:\", x.shape)\n",
    "ic(\"Labels:\", y)\n",
    "plt.imshow(torchvision.utils.make_grid(x)[0], cmap=\"Greys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUNet(nn.Module):\n",
    "    def __init__(self, ctx_nb_feats:int, in_channels:int=1, out_channels:int=1):\n",
    "        super().__init__()\n",
    "        self.d1 = nn.Conv2d(in_channels, 64, kernel_size=5, padding=2)\n",
    "        self.d2 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
    "        self.d3 = nn.Conv2d(128, 256, kernel_size=5, padding=2)\n",
    "\n",
    "        self.u1= nn.Conv2d(256, 128, kernel_size=5, padding=2)\n",
    "        self.u2= nn.Conv2d(128, 64, kernel_size=5, padding=2)\n",
    "        self.u3= nn.Conv2d(64, out_channels, kernel_size=5, padding=2)\n",
    "\n",
    "        self.ce2 = nn.Embedding(ctx_nb_feats,128)\n",
    "        self.te2 = nn.Embedding(1,128)\n",
    "\n",
    "        self.ce3 = nn.Embedding(ctx_nb_feats,64)\n",
    "        self.te3 = nn.Embedding(1,64)\n",
    "\n",
    "        self.act = nn.SiLU()\n",
    "        self.downsample = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "\n",
    "    def forward(self, x, t, c=None):\n",
    "        xd1 = self.act(self.d1(x))\n",
    "        xmd1 = self.downsample(xd1)\n",
    "        xd2 = self.act(self.d2(xmd1))\n",
    "        xmd2 =self.downsample(xd2)\n",
    "        xd3 = self.act(self.d3(xmd2))\n",
    "\n",
    "        xu1 = self.act(self.u1(xd3))\n",
    "        xus2 = self.upsample(xu1)\n",
    "        xus2 = xus2 + xd2\n",
    "        h2_dim  = xus2.shape[1] # the dim of hidden\n",
    "        t2_emb = self.te2(t).view(-1, h2_dim, 1,1)\n",
    "        c2_emb = self.ce2(c).view(-1, h2_dim, 1,1)\n",
    "        xus2 = c2_emb * xus2 + t2_emb\n",
    "        xu2 = self.act(self.u2(xus2))\n",
    "\n",
    "        xus3 = self.upsample(xu2)\n",
    "        xus3 = xus3 + xd1\n",
    "        h3_dim  = xus3.shape[1] # the dim of hidden\n",
    "        t3_emb = self.te3(t).view(-1, h3_dim, 1,1)\n",
    "        c3_emb = self.ce3(c).view(-1, h3_dim, 1,1)\n",
    "        xus2 = c3_emb * xus3 + t3_emb\n",
    "        xu3 = self.act(self.u3(xus3))\n",
    "\n",
    "        return xu3\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "x, y = next(iter(train_dataloader))\n",
    "model = BasicUNet(ctx_nb_feats=9).to(device)\n",
    "#x = torch.rand(8, 1, 28, 28)\n",
    "t = torch.zeros(x.shape[0]).long().to(device)\n",
    "#oh_y = oh_y.to(device)\n",
    "x = x.to(device)\n",
    "y = y.long().to(device)\n",
    "ic(t.shape, y.shape)\n",
    "ux = model(x,t, y)\n",
    "ic(ux.shape, x.shape)\n",
    "ic(torchvision.utils.make_grid(x.cpu())[0].shape)\n",
    "plt.imshow(torchvision.utils.make_grid(x.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "plt.imshow(torchvision.utils.make_grid(ux.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicUNetOld(nn.Module):\n",
    "    \"\"\"A minimal UNet implementation.\"\"\"\n",
    "    #TODO: add time embedding and a class embedding\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, ctx_nb_feats:int=0):\n",
    "        super().__init__()\n",
    "        self.down_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(in_channels, 32, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "            ]\n",
    "        )\n",
    "        self.time_embeds = nn.ModuleList([nn.Embedding(1,64), nn.Embedding(1,32)])\n",
    "        self.ctx_embeds = nn.ModuleList([nn.Embedding(ctx_nb_feats,64), nn.Embedding(ctx_nb_feats,32)])\n",
    "        self.up_layers = torch.nn.ModuleList(\n",
    "            [\n",
    "                nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
    "                nn.Conv2d(32, out_channels, kernel_size=5, padding=2),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.act = nn.SiLU()  # The activation function\n",
    "        self.downscale = nn.MaxPool2d(2)\n",
    "        self.upscale = nn.Upsample(scale_factor=2)\n",
    "\n",
    "    def forward(self, x, t, c=None):\n",
    "        h = []\n",
    "        for i, l in enumerate(self.down_layers):\n",
    "            x = self.act(l(x))  # Through the layer and the activation function\n",
    "            if i < 2:  # For all but the third (final) down layer:\n",
    "                h.append(x)  # Storing output for skip connection\n",
    "                x = self.downscale(x)  # Downscale ready for the next layer\n",
    "        ic(\"after downscale layers\", x.shape)\n",
    "        for i, l in enumerate(self.up_layers):\n",
    "\n",
    "            if i > 0:  # For all except the first up layer\n",
    "                ic(\"before upscale\",i, x.shape)\n",
    "                x = self.upscale(x)  # Upscale\n",
    "                ic(\"after upscale\",i,x.shape)\n",
    "\n",
    "                x += h.pop()  # Fetching stored output (skip connection)\n",
    "                h_dim  = x.shape[1] # the dim of hidden\n",
    "                t_emb = self.time_embeds[i-1](t).view(-1, h_dim, 1,1)\n",
    "                ctx_emb = self.ctx_embeds[i-1](c).view(-1, h_dim, 1,1)\n",
    "                ic(x.shape, ctx_emb.shape, t_emb.shape)\n",
    "                x = ctx_emb * x + t_emb\n",
    "            ic(\"before uplayer + activation\",i, x.shape)\n",
    "            x = self.act(l(x))  # Through the layer and the activation function\n",
    "            ic(\"after uplayer + activation\",i, x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = BasicUNetOld().to(device)\n",
    "#x = torch.rand(8, 1, 28, 28)\n",
    "t = torch.zeros(x.shape[0]).long().to(device)\n",
    "#oh_y = oh_y.to(device)\n",
    "x = x.to(device)\n",
    "ic(t.shape, y.shape)\n",
    "ux = model(x,t, y)\n",
    "ic(ux.shape, x.shape)\n",
    "plt.imshow(torchvision.utils.make_grid(x.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n",
    "plt.imshow(torchvision.utils.make_grid(ux.cpu())[0], cmap=\"Greys\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cop-diffusion-04jlPuwc-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
